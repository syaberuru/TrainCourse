{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import *\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder,TrainValidationSplit\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- results: string (nullable = true)\n",
      " |-- content: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.option(\"header\", \"false\").option(\"delimiter\", \"\\t\").csv(\"../data/SMSSpamCollection\").withColumnRenamed(\"_c0\", \"results\").withColumnRenamed(\"_c1\", \"content\")\n",
    "#读入已经解压的csv文件，以tab为分割，并将列名更改\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|results|\n",
      "+-------+\n",
      "|    ham|\n",
      "|   spam|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('results').distinct().show()#计算结果种类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|results|             content|\n",
      "+-------+--------------------+\n",
      "|    ham|Go until jurong p...|\n",
      "|    ham|Ok lar... Joking ...|\n",
      "|   spam|Free entry in 2 a...|\n",
      "|    ham|U dun say so earl...|\n",
      "|    ham|Nah I don't think...|\n",
      "+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#清洗数据:因为空白的短信内容可能也是垃圾短信，所以应该清洗掉评价为空的数据\n",
    "#df0 = df.select(df).where(df['content'].isNotNull())\n",
    "df0 = df.filter(df['results']!='null')\n",
    "df0.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|             content|\n",
      "+-----+--------------------+\n",
      "|    0|Go until jurong p...|\n",
      "|    0|Ok lar... Joking ...|\n",
      "|    1|Free entry in 2 a...|\n",
      "|    0|U dun say so earl...|\n",
      "|    0|Nah I don't think...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labeledData = df0.select(when(df0.results == 'ham', 0)#给数据打标签\n",
    "                        .when(df0.results == 'spam', 1)\n",
    "                        .otherwise(1)\n",
    "                        .alias('label'), \n",
    "                        'content')\n",
    "labeledData.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|label|             content|               words|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|    0| &lt;#&gt;  mins ...|[, &lt;#&gt;, , m...|(262144,[19036,27...|[5.57905023590004...|[0.99623805539995...|       0.0|\n",
      "|    0| and  picking the...|[, and, , picking...|(262144,[34116,59...|[6.32966951150726...|[0.99822054928135...|       0.0|\n",
      "|    0| says that he's q...|[, says, that, he...|(262144,[8538,187...|[6.96802242869682...|[0.99905937263780...|       0.0|\n",
      "|    0|\"Response\" is one...|[\"response\", is, ...|(262144,[12524,21...|[4.17726538284082...|[0.98489137202011...|       0.0|\n",
      "|    0|\"Speak only when ...|[\"speak, only, wh...|(262144,[24980,55...|[6.13911967894033...|[0.99784782038902...|       0.0|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#开始训练\n",
    "\n",
    "trainingData, testData = labeledData.randomSplit([0.8, 0.2])#将数据集随机分为训练集与测试集\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"content\", outputCol=\"words\")#切割单词\n",
    "hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=\"features\")#将单词映射为特征\n",
    "lr = LogisticRegression(maxIter=100, regParam=0.01)#maxIter=100: 最大迭代次数/并行度，regParam=0.0: 正则化惩罚程度参数\n",
    "#在线性模型中，为了预防overfitting过度拟合，添加了惩罚项\n",
    "pipeline = Pipeline(stages=[tokenizer, hashingTF, lr])#传入数据与参数,并行化处理\n",
    "\n",
    "model = pipeline.fit(trainingData)#拟合\n",
    "\n",
    "predictionsDf = model.transform(testData)#读取包含特征向量的列，预测每个特征向量的标签，然后输出一个新的，其中预测的标签追加为列。\n",
    "predictionsDf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Successes = predictionsDf.where('label == prediction')\n",
    "unSuccesses = predictionsDf.where('label != prediction')\n",
    "\n",
    "#Successes.select('label','content','prediction').take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(label=0, content=\"Forgot you were working today! Wanna chat, but things are ok so drop me a text when you're free / bored etc and i'll ring. Hope all is well, nose essay and all xx\", prediction=1.0),\n",
       " Row(label=1, content='0A$NETWORKS allow companies to bill for SMS, so they are responsible for their \"suppliers\", just as a shop has to give a guarantee on what they sell. B. G.', prediction=0.0),\n",
       " Row(label=1, content=\"1000's of girls many local 2 u who r virgins 2 this & r ready 2 4fil ur every sexual need. Can u 4fil theirs? text CUTE to 69911(£1.50p. m)\", prediction=0.0),\n",
       " Row(label=1, content='As a SIM subscriber, you are selected to receive a Bonus! Get it delivered to your door, Txt the word OK to No: 88600 to claim. 150p/msg, EXP. 30Apr', prediction=0.0),\n",
       " Row(label=1, content='Babe: U want me dont u baby! Im nasty and have a thing 4 filthyguys. Fancy a rude time with a sexy bitch. How about we go slo n hard! Txt XXX SLO(4msgs)', prediction=0.0),\n",
       " Row(label=1, content=\"Bored of speed dating? Try SPEEDCHAT, txt SPEEDCHAT to 80155, if you don't like em txt SWAP and get a new chatter! Chat80155 POBox36504W45WQ 150p/msg rcd 16\", prediction=0.0),\n",
       " Row(label=1, content='Claim a 200 shopping spree, just call 08717895698 now! Have you won! MobStoreQuiz10ppm', prediction=0.0),\n",
       " Row(label=1, content='Dear Voucher Holder 2 claim your 1st class airport lounge passes when using Your holiday voucher call 08704439680. When booking quote 1st class x 2', prediction=0.0),\n",
       " Row(label=1, content='Dear Voucher holder Have your next meal on us. Use the following link on your pc 2 enjoy a 2 4 1 dining experiencehttp://www.vouch4me.com/etlp/dining.asp', prediction=0.0),\n",
       " Row(label=1, content='Did you hear about the new \"Divorce Barbie\"? It comes with all of Ken\\'s stuff!', prediction=0.0)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unSuccesses.select('label','content','prediction').take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 1105 inspections and there were 1060 successful predictions\n",
      "This is a 95% success rate\n"
     ]
    }
   ],
   "source": [
    "numSuccesses = Successes.count()#计算标签与预测成功的数量\n",
    "numInspections = predictionsDf.count()\n",
    "\n",
    "print (\"There were %d inspections and there were %d successful predictions\" % (numInspections, numSuccesses))\n",
    "print(\"This is a %d%% success rate\" % (float(numSuccesses) / float(numInspections) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#F1分数(F1 Score),是统计学中用来衡量二分类(或多任务二分类)模型精确度的一种指标。\n",
    "#它同时兼顾了分类模型的准确率和召回率。\n",
    "#F1分数可以看作是模型准确率和召回率的一种加权平均,它的最大值是1,最小值是0,值越大意味着模型越好。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1score 0.9767921609076844\n"
     ]
    }
   ],
   "source": [
    "prediction0=predictionsDf.where('label == 0')\n",
    "TP=prediction0.where('prediction == 0').count()\n",
    "precision=TP/prediction0.count()\n",
    "real0=predictionsDf.where('prediction == 0').count()\n",
    "recall=TP/real0\n",
    "F1score=(2*precision*recall)/(precision+recall)\n",
    "print('F1score',F1score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#优化调参：交叉验证\n",
    "#因为样本较小因此采用交叉验证\n",
    "#交叉验证(CrossValidator)将数据集切分成k折数据集，分别用于训练和测试。\n",
    "#通过交叉验证选择模型，参数网格有 3 个值，有 2 个值，并使用 2 个折叠\n",
    "#现在，我们将管道视为估计器，将其包装在CrossValidator实例中。\n",
    "#这将使我们能够共同选择所有管道阶段的参数。\n",
    "#交叉验证程序需要一个估计器、一组估计器参数映射和一个评估器。\n",
    "#我们使用ParamGridBuilder构建参数网格以进行搜索。\n",
    "#hashingTF有3个值。lr.regParam的numFeatures和2个值，\n",
    "#此网格将具有3 x 2=6个参数设置，可供CrossValidator选择。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData, testData = labeledData.randomSplit([0.8, 0.2])\n",
    "tokenizer = Tokenizer(inputCol=\"content\", outputCol=\"words\")\n",
    "hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=\"features\")\n",
    "lr = LogisticRegression(maxIter=10)\n",
    "pipeline = Pipeline(stages=[tokenizer, hashingTF, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = ParamGridBuilder().addGrid(hashingTF.numFeatures, [10, 100, 1000]) .addGrid(lr.regParam, [0.1, 0.01]) .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(),#用于二分类问题\n",
    "                          numFolds=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvModel = crossval.fit(trainingData)\n",
    "prediction = cvModel.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Successes = prediction.where('label == prediction')\n",
    "unSuccesses = prediction.where('label != prediction')\n",
    "\n",
    "#Successes.select('label','content','prediction').take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(label=0, content=\"Forgot you were working today! Wanna chat, but things are ok so drop me a text when you're free / bored etc and i'll ring. Hope all is well, nose essay and all xx\", prediction=1.0),\n",
       " Row(label=1, content='0A$NETWORKS allow companies to bill for SMS, so they are responsible for their \"suppliers\", just as a shop has to give a guarantee on what they sell. B. G.', prediction=0.0),\n",
       " Row(label=1, content=\"1000's of girls many local 2 u who r virgins 2 this & r ready 2 4fil ur every sexual need. Can u 4fil theirs? text CUTE to 69911(£1.50p. m)\", prediction=0.0),\n",
       " Row(label=1, content='As a SIM subscriber, you are selected to receive a Bonus! Get it delivered to your door, Txt the word OK to No: 88600 to claim. 150p/msg, EXP. 30Apr', prediction=0.0),\n",
       " Row(label=1, content='Babe: U want me dont u baby! Im nasty and have a thing 4 filthyguys. Fancy a rude time with a sexy bitch. How about we go slo n hard! Txt XXX SLO(4msgs)', prediction=0.0),\n",
       " Row(label=1, content=\"Bored of speed dating? Try SPEEDCHAT, txt SPEEDCHAT to 80155, if you don't like em txt SWAP and get a new chatter! Chat80155 POBox36504W45WQ 150p/msg rcd 16\", prediction=0.0),\n",
       " Row(label=1, content='Claim a 200 shopping spree, just call 08717895698 now! Have you won! MobStoreQuiz10ppm', prediction=0.0),\n",
       " Row(label=1, content='Dear Voucher Holder 2 claim your 1st class airport lounge passes when using Your holiday voucher call 08704439680. When booking quote 1st class x 2', prediction=0.0),\n",
       " Row(label=1, content='Dear Voucher holder Have your next meal on us. Use the following link on your pc 2 enjoy a 2 4 1 dining experiencehttp://www.vouch4me.com/etlp/dining.asp', prediction=0.0),\n",
       " Row(label=1, content='Did you hear about the new \"Divorce Barbie\"? It comes with all of Ken\\'s stuff!', prediction=0.0)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unSuccesses.select('label','content','prediction').take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 1149 inspections and there were 1103 successful predictions\n",
      "This is a 95% success rate\n"
     ]
    }
   ],
   "source": [
    "numSuccesses = prediction.where('label == prediction').count()#计算标签与预测成功的数量\n",
    "numInspections = prediction.count()\n",
    "\n",
    "print (\"There were %d inspections and there were %d successful predictions\" % (numInspections, numSuccesses))\n",
    "print(\"This is a %d%% success rate\" % (float(numSuccesses) / float(numInspections) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1score 0.9773622047244095\n"
     ]
    }
   ],
   "source": [
    "prediction0=prediction.where('label == 0')\n",
    "TP=prediction0.where('prediction == 0').count()\n",
    "precision=TP/prediction0.count()\n",
    "real0=prediction.where('prediction == 0').count()\n",
    "recall=TP/real0\n",
    "F1score=(2*precision*recall)/(precision+recall)\n",
    "print('F1score',F1score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
